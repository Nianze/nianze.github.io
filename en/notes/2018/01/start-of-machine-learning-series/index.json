{
  "title": "Machine learning overview",
  "content": "My first post in the new machine learning series.\nAlthough I\u0026rsquo;ve chosen https://nianze.ml as my personal website domain name, I haven\u0026rsquo;t really posted any article on Machine Learning at all, which may somehow be misleading. Considering it\u0026rsquo;s new year and my website has just been re-designed, it\u0026rsquo;s perfect time for new plans, so I\u0026rsquo;ve made a dicision to begin a new series related to ml: I\u0026rsquo;ll write down learning notes during my self-study in machine learning. Recently I\u0026rsquo;m reading the book Hands-On Machine Learning with Scikit-Learn and TensorFlow by Aurélien Géron, which should be a good start for this new series.\nAt first the post is intended to be written in Chinese, but considering there\u0026rsquo;re so many technique terms in English that I do not know the exact Chinese translation, I\u0026rsquo;ll just start with English.\nAs the first post in this series, let\u0026rsquo;s just take a overview on machine learning system.\nTypes of machine learning There are broadly three ways to classify machine learning systems, and each of these three could be further categorized into multiple sub-categories:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Machine learning system ├── trained with supervision or without │ ├── supervised learning │ │ ├── k-Nearest Neighbors │ │ ├── Linear Regression │ │ ├── Logistic Regression │ │ ├── Support Vector Machines (SVMs) │ │ ├── Decision Trees and Random Forests │ │ └── Neural networks │ ├── unsupervised learning │ │ ├── clustering │ │ │ ├── k-Means │ │ │ ├── Hierarchical Cluster Analysis (HCA) │ │ │ └── Expectation Maximization │ │ ├── Visualization and dimensionality reduction │ │ │ ├── Principal Component Analysis (PCA) │ │ │ ├── Kernel PCA │ │ │ ├── Locally-Linear Embedding (LLE) │ │ │ └── t-distributed Stochastic Neighbor Embedding (t-SNE) │ │ └── Association rule learning │ │ ├── Apriori │ │ └── Eclat │ ├── semisupervised learning │ └── reinforcement learning ├── learn incrementally or in a whole batch │ ├── online learning (incremental learning) │ │ ├── adapting rapidly to changing data and autonomous system │ │ └── out-of-core learning (training on large quantities of data) │ └── batch learning └── predict based on a model or not ├── instance-based learning (using a similarity measure) └── model-based learning Main challenges of machine learning Bad data Insufficient quantity of training data Nonrepresentative training data Poor-quality data Irrelevant features Bad algorithm Overfitting the training data Underfitting the training data We reduce overfitting by constraining the degrees of freedom the model has, which is called regularization. The amount of regularization can be controlled by a hyperparameter, which is a parameter of the learning algorithm (not of the model). The larger the hyperparameter, the smaller the model parameter, ending up with more constrain we apply to the model and less degrees of freedom.\nOn the other side, to solve underfitting problem, we may consider:\nselect more powerful model with more parameters feed better fetures reduce the constraints (e.g., reducing the regularization hyperparameter) Testing and validating Usually we split data into three groups:\ntraining set validation set test set And take following common workflow:\ntrain multiple models with various hyperparameters using the training set select the model and hyperparameters tht perform best on the validation set run a single final tets against the test set to get an estimate of the generalization error (out-of-sample error) Further, we can use cross-validation technique to reuse data:\nsplit trainig set into complementary subsets train each model against a different combination of these subsets and validate against the remaining parts select the model type and hyperparameters with best performance train the final model by feeding the full training set to the chosen model and hyperparameters measure the generalized error on the test set Concept checkout: How would you define Machine Learning?\nML is a system that can learn from data. Specifically, given performance measure, the learning will result in better performance at some tasks. Can you name four types of problems where it shines?\nComplex problems without known algorithmic solution Long hand-tuned rules System that needs to adapt to fluctuating environment Data mining (help humans learn) What is a labeled training set?\nIt\u0026rsquo;s a training set that contains the desired solution (a label) for each instance What are the two most common supervised tasks?\nRegression and classification What is the purpose of test set and validation set?\nA test set is used to estimate the generalization error that a model will make on new instances, before the model is launched in production. A validation set is used to compare models. It makes it possible to select the best model and tune the hyperparameters. Why would you prefer cross-validation?\nCross-validation is a technique that makes it possible to compare models (for model selection and hyperparameter tuning) without the need for a separate validation set. This saves precious training data. ",
  "summary": "My first post in the new machine learning series.\n",
  "date": "2018-01-04T00:00:00Z",
  "lastmod": "2018-01-04T00:00:00Z",
  "permalink": "https://nianze.github.io/en/notes/2018/01/start-of-machine-learning-series/",
  "type": "notes",
  "kind": "page",
  "section": "notes",
  "tags": ["technique","machine learning"],
  "categories": ["coding"],
  "series": null
}
