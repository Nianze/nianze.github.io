{
  "title": "[MECpp]Item-18 Amortize the Cost of Expected Computations",
  "content": "The old Computer Science story: trade space for time1.\nIn order to improve program efficiency, we may use lazy evaluation (MECpp item 17), which is a technique for improving the efficiency of programs where results are not always needed. On the other side, when we must support operations whose results are almost always needed or whose results are often needed more than once, we may adopt \u0026ldquo;over-eager evaluation to amortize the cost of anticipated computations, such as caching and prefetching.\nCaching Say we\u0026rsquo;re writing a program to provide information about employees, and one of the pieces of information we expect to request frequently is an employee\u0026rsquo;s cubicle number, which is stored in a database, but the database is not optimized to find it. In this case, we could cache the cubicle numbers to save the subsequent database lookups.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int findCubicleNumber(const string\u0026amp; employeeName) { typedef map\u0026lt;string, int\u0026gt; CubicleMap; static CubicleMap cubes; CubicleMap::iterator it = cubes.find(employeeName); if (it == cubes.end()) { int cubicle = // db query for the cubicle number cubes[employeeName] = cubicle; return cubicle; } else { return it-\u0026gt;second; // or \u0026#34;(*it).second\u0026#34; if compiler does not support \u0026#34;-\u0026gt;\u0026#34; for \u0026#34;it\u0026#34; object } } Prefetching According to the infamous locality of reference phenomenon, if data in one place is requested, it\u0026rsquo;s quite common to want nearby data, too, which justifies disk caches, memory caches for both instructions and data, and instruction prefetches.\nAdopting similar concept, we can use similar strategy when writing a template for dynamic arrays, which will automatically extend themselves:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 template\u0026lt;class T\u0026gt; class DynArray {...}; template\u0026lt;class T\u0026gt; T\u0026amp; DynArray\u0026lt;T\u0026gt;::operator[](int index) { if (index \u0026lt; 0) { throw an exception; } if (index \u0026gt; the current maximum index value) { int diff = index - the current maximum index value; call new to allocate enough additional memory so that (index+diff) is valid; } return the indexth element of the array; } This operator[] function allocates twice as much memory as needed each time the array must be extended, so that it saves one memory allocation when its logical size is extended twice in the following case:\n1 2 3 4 DynArray\u0026lt;double\u0026gt; a; // only a[0] is valid a[22] = 3.5; // new is called to expand a\u0026#39;s storage through index 44, // a\u0026#39;s logical size is 23 a[32] = 0; // a\u0026#39;s logical size is now 33, without new being called Not always. Using large objects means fewer fit on a virtual memory or cache page. In rare cases, making objects bigger reduces the performance of the software due to the increased paging activity and/or the decreased cache hit rate.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n",
  "summary": "The old Computer Science story: trade space for time1.\n",
  "date": "2018-04-12T15:31:55-04:00",
  "lastmod": "2018-04-12T15:31:55-04:00",
  "permalink": "https://nianze.github.io/en/notes/2018/04/amortize-the-cost-of-expected-computations/",
  "type": "notes",
  "kind": "page",
  "section": "notes",
  "tags": ["technique","cpp"],
  "categories": ["coding"],
  "series": ["effective c++"]
}
